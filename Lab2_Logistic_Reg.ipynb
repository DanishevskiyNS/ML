{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/dataset/81/pen+based+recognition+of+handwritten+digits  \n",
    "https://archive.ics.uci.edu/dataset/59/letter+recognition   \n",
    "https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety  class\n",
       "0     vhigh  vhigh      2       2    small    low  unacc\n",
       "1     vhigh  vhigh      2       2    small    med  unacc\n",
       "2     vhigh  vhigh      2       2    small   high  unacc\n",
       "3     vhigh  vhigh      2       2      med    low  unacc\n",
       "4     vhigh  vhigh      2       2      med    med  unacc\n",
       "...     ...    ...    ...     ...      ...    ...    ...\n",
       "1723    low    low  5more    more      med    med   good\n",
       "1724    low    low  5more    more      med   high  vgood\n",
       "1725    low    low  5more    more      big    low  unacc\n",
       "1726    low    low  5more    more      big    med   good\n",
       "1727    low    low  5more    more      big   high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "df = pd.read_csv('data/cars/car.data' ,names=header)\n",
    "\n",
    "#header = ['class', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
    "#df = pd.read_csv('letter_recognition/letter-recognition.data', names=header)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчёт сэмплов каждого класса\n",
    "def calc_classes_exmpls(dataframe):\n",
    "    for cls in dataframe['class'].unique():\n",
    "        print(f\"{cls}: {len(dataframe[dataframe['class'] == cls])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns 'buying' unique values are ['vhigh' 'high' 'med' 'low']\n",
      "For columns 'maint' unique values are ['vhigh' 'high' 'med' 'low']\n",
      "For columns 'doors' unique values are ['2' '3' '4' '5more']\n",
      "For columns 'persons' unique values are ['2' '4' 'more']\n",
      "For columns 'lug_boot' unique values are ['small' 'med' 'big']\n",
      "For columns 'safety' unique values are ['low' 'med' 'high']\n",
      "For columns 'class' unique values are ['unacc' 'acc' 'vgood' 'good']\n",
      "\n",
      "unacc: 1210\n",
      "acc: 384\n",
      "vgood: 65\n",
      "good: 69\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"For columns '{column}' unique values are {df[column].unique()}\")\n",
    "print()\n",
    "calc_classes_exmpls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[df['class'] == 'unacc'].sample(826)\n",
    "new_df = df.drop(index=tmp.index)\n",
    "#new_df = df.drop(df[df['class'] == 'unacc'].sample(826))\n",
    "calc_classes_exmpls(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "original_classes = np.unique(df['class'].values)\n",
    "for column_name in df.columns:\n",
    "    df[column_name] = le.fit_transform(df[column_name])\n",
    "y = df['class']\n",
    "X = df.loc[:, df.columns != 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "Y=y.values.astype(int)\n",
    "feature_num = X.shape[1]\n",
    "classes_num = len(pd.unique(y))\n",
    "print('Numb of features: ', feature_num)\n",
    "print('Numb of classes: ', classes_num)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(x_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(criterion='log_loss', random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train_lr = preprocessing.StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test_lr = preprocessing.StandardScaler().fit(x_test).transform(x_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=1, max_iter=1000, penalty=None, fit_intercept=False)\n",
    "clf.fit(x_train_lr, y_train)\n",
    "y_preds = clf.predict(x_test_lr)\n",
    "print(clf.score(x_test_lr, y_test))\n",
    "print(classification_report(y_test, y_preds, target_names=list(map(str, original_classes.tolist())), digits=2, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-10\n",
    "class Softmax:\n",
    "    @staticmethod\n",
    "    def activation(z):\n",
    "        z_exp = np.exp(z)\n",
    "        return z_exp / np.sum(z_exp, axis=1).reshape(-1,1)\n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        softm = Softmax.activation(z)\n",
    "        return (softm*(1-softm))\n",
    "    \n",
    "class CrossEntropy:\n",
    "    @staticmethod\n",
    "    def forward(y_true, y_pred):\n",
    "        return np.mean(-1 * y_true * np.log(y_pred + epsilon) + (1 - y_true)*np.log(1-y_pred+epsilon))\n",
    "    @staticmethod\n",
    "    def backward(y_true, y_pred):\n",
    "        return -y_true / y_pred + (1-y_true)/(1-y_pred)\n",
    "\n",
    "\n",
    "def data_gen(x, y, batch_size):\n",
    "    n_samples = x.shape[0]\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        yield(x[i:i+batch_size, :], y[i:i+batch_size, :])\n",
    "\n",
    "def get_onehot(y, classes=[]):\n",
    "    classes = np.unique(y)\n",
    "    labels = {c:i for i,c in enumerate(classes)}\n",
    "    return np.eye(len(classes))[np.vectorize(lambda cls: labels[cls])(y).reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicRegressor:\n",
    "    def __init__(self, num_features, num_classes, orig_classes) -> None:\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.orig_classes = orig_classes\n",
    "\n",
    "        self._init_weights()\n",
    "        self._init_biases()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        limit = np.sqrt(6/(self.num_features*self.num_features))\n",
    "        self.weights = np.random.uniform(-limit, limit, size=(self.num_classes, self.num_features))\n",
    "    \n",
    "    def _init_biases(self):\n",
    "        self.biases = np.random.random(size=(1, self.num_classes))\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        return CrossEntropy.forward(y_true, y_pred)\n",
    "\n",
    "    def loss_d(self, y_pred, y_true):\n",
    "        pass\n",
    "        error = (y_pred - y_true)\n",
    "        return error\n",
    "        \n",
    "\n",
    "    def activation(self, x):\n",
    "        return Softmax.activation(x)\n",
    "    def activation_d(self, y):\n",
    "        return Softmax.derivative(y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.inp = x\n",
    "        y = np.matmul(x, self.weights.T) + self.biases\n",
    "        return self.activation(y.astype(float))\n",
    "    \n",
    "    def _forward(self, x):\n",
    "        self.inp = x\n",
    "        y_pred = np.matmul(x, self.weights.T) + self.biases\n",
    "        return y_pred\n",
    "    \n",
    "    def _backward(self, loss_d, lr=0.01):\n",
    "        self.weights = self.weights - lr * np.matmul(loss_d.T, self.inp)\n",
    "        self.biases -= lr * loss_d.mean()\n",
    "  \n",
    "    \n",
    "    def train(self, x_train, y_train, x_test=None, y_test=None, epochs=10, lr=0.01, batch_size=351):\n",
    "        losses = np.array([])\n",
    "        accuracy = np.array([])\n",
    "        y_train = get_onehot(y_train)\n",
    "        \n",
    "        for epoch in range(epochs): \n",
    "            for x, y in data_gen(x_train, y_train, batch_size=batch_size):\n",
    "                y_pred = self.predict(x)\n",
    "                epoch_loss = self.loss(y_pred, y).mean()\n",
    "                \n",
    "                loss_d = self.loss_d(y_pred, y)\n",
    "                self._backward(loss_d, lr=lr)\n",
    "            \n",
    "            losses = np.append(losses, epoch_loss)\n",
    "\n",
    "            if not epoch%1000: print(f'Loss on {epoch} epoch: ', losses[-1])\n",
    "        return losses, accuracy\n",
    "    \n",
    "    def score(self, x_test, y_test, threshold=0.5):\n",
    "       \n",
    "        # Преобразование предсказаний в Dummies\n",
    "        y_preds = self.predict(x_test)\n",
    "        y_preds[y_preds>=threshold] = 1\n",
    "        y_preds[y_preds<threshold] = 0\n",
    "        y_preds = y_preds.astype(bool)\n",
    "        \n",
    "        # Аналогично с GT значениями\n",
    "        y_true = get_onehot(y_test)\n",
    "        y_true = y_true.astype(bool)\n",
    "        # Получаем метрики\n",
    "        print(classification_report(y_true, y_preds, target_names=list(map(str, self.orig_classes.tolist())), digits=2, zero_division=True))\n",
    "        acc = accuracy_score(y_true, y_preds)\n",
    "        print('Accuracy: ', acc)\n",
    "        return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_features = x_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(num_classes)\n",
    "\n",
    "x_train_scaled = preprocessing.StandardScaler().fit(x_train).transform(x_train)\n",
    "x_test_scaled = preprocessing.StandardScaler().fit(x_test).transform(x_test)\n",
    "\n",
    "LRC = LogicRegressor(\n",
    "                    num_features=num_features, \n",
    "                    num_classes=num_classes, \n",
    "                    orig_classes=original_classes\n",
    "                    )\n",
    "losses, accuracy = LRC.train(x_train, y_train, x_test, y_test, epochs=2000, batch_size=len(x_train), lr=1e-5)\n",
    "LRC.score(x_test, y_test)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.title(\"Loss during training\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "if accuracy.shape[0] > 0:\n",
    "    plt.plot(np.arange(len(accuracy)), accuracy)\n",
    "    plt.title(\"Accuracy during training\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tree import CART\n",
    "from forest import RandomForest\n",
    "\n",
    "def get_accuracy(y_true, y_preds):\n",
    "    correct = np.sum(y_preds == y_true)\n",
    "\n",
    "    return correct / y_true.shape[0]\n",
    "\n",
    "df = pd.read_csv(\"cars/car.data\", header=None).values\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, shuffle=True)\n",
    "#x_test, y_test\n",
    "tree_1 = CART(max_depth=10)\n",
    "tree_1.fit(df_train)\n",
    "\n",
    "y_preds_1 = tree_1.predict(df_test[:, :-1])\n",
    "\n",
    "print(get_accuracy(df_test[:, -1], y_preds_1))\n",
    "\n",
    "forest = RandomForest(30, 30, 100)\n",
    "forest.fit(df_train)\n",
    "y_preds = forest.predict(df_test[:, :-1])\n",
    "\n",
    "# print(y_preds)\n",
    "# print(accuracy_score(df_test[:, :-1], y_preds))\n",
    "\n",
    "print(get_accuracy(df_test[:, -1], y_preds))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
